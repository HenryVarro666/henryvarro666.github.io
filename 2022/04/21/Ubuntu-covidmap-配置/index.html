<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.1.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"henryvarro666.github.io","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":true},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"./public/search.xml"};
  </script>

  <meta name="description" content="为project做准备（一个月用完跑路，芜湖）">
<meta property="og:type" content="article">
<meta property="og:title" content="Ubuntu(covidmap) 配置">
<meta property="og:url" content="https://henryvarro666.github.io/2022/04/21/Ubuntu-covidmap-%E9%85%8D%E7%BD%AE/index.html">
<meta property="og:site_name" content="我见青山多妩媚，料青山 见我应如是">
<meta property="og:description" content="为project做准备（一个月用完跑路，芜湖）">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://raw.githubusercontent.com/HenryVarro666/images/master/images/202204212015069.png">
<meta property="og:image" content="https://raw.githubusercontent.com/HenryVarro666/images/master/images/202204212121300.png">
<meta property="og:image" content="https://raw.githubusercontent.com/HenryVarro666/images/master/images/202204212126250.png">
<meta property="og:image" content="https://raw.githubusercontent.com/HenryVarro666/images/master/images/202204212146090.png">
<meta property="og:image" content="https://raw.githubusercontent.com/HenryVarro666/images/master/images/202204212150475.png">
<meta property="og:image" content="https://raw.githubusercontent.com/HenryVarro666/images/master/images/202204212155536.png">
<meta property="og:image" content="https://raw.githubusercontent.com/HenryVarro666/images/master/images/202204212219514.png">
<meta property="og:image" content="https://raw.githubusercontent.com/HenryVarro666/images/master/images/202204212243291.png">
<meta property="og:image" content="https://raw.githubusercontent.com/HenryVarro666/images/master/images/202204212244465.png">
<meta property="og:image" content="https://raw.githubusercontent.com/HenryVarro666/images/master/images/202204212304710.png">
<meta property="og:image" content="https://raw.githubusercontent.com/HenryVarro666/images/master/images/202204212309755.png">
<meta property="og:image" content="https://raw.githubusercontent.com/HenryVarro666/images/master/images/202204212312632.png">
<meta property="og:image" content="https://raw.githubusercontent.com/HenryVarro666/images/master/images/202204212314047.png">
<meta property="og:image" content="https://raw.githubusercontent.com/HenryVarro666/images/master/images/202204212356322.png">
<meta property="og:image" content="https://raw.githubusercontent.com/HenryVarro666/images/master/images/202204281044123.png">
<meta property="og:image" content="https://raw.githubusercontent.com/HenryVarro666/images/master/images/202204281101626.png">
<meta property="og:image" content="https://raw.githubusercontent.com/HenryVarro666/images/master/images/202204281047487.png">
<meta property="article:published_time" content="2022-04-22T00:11:05.000Z">
<meta property="article:modified_time" content="2022-04-28T16:05:55.597Z">
<meta property="article:author" content="Chao Cao">
<meta property="article:tag" content="Ubuntu">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/HenryVarro666/images/master/images/202204212015069.png">

<link rel="canonical" href="https://henryvarro666.github.io/2022/04/21/Ubuntu-covidmap-%E9%85%8D%E7%BD%AE/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Ubuntu(covidmap) 配置 | 我见青山多妩媚，料青山 见我应如是</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">我见青山多妩媚，料青山 见我应如是</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Chao の Blog</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://henryvarro666.github.io/2022/04/21/Ubuntu-covidmap-%E9%85%8D%E7%BD%AE/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/head2.jpg">
      <meta itemprop="name" content="Chao Cao">
      <meta itemprop="description" content="为天地立心，为生民立命，为往圣继绝学，为万世开太平">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="我见青山多妩媚，料青山 见我应如是">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Ubuntu(covidmap) 配置
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-04-21 19:11:05" itemprop="dateCreated datePublished" datetime="2022-04-21T19:11:05-05:00">2022-04-21</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-04-28 11:05:55" itemprop="dateModified" datetime="2022-04-28T11:05:55-05:00">2022-04-28</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E4%B8%93%E4%B8%9A%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/" itemprop="url" rel="index"><span itemprop="name">专业相关知识</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>8.8k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>8 mins.</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>为project做准备（一个月用完跑路，芜湖）</p>
<span id="more"></span>

<p>设置root和password方便远程登录（已写）</p>
<p>然后就是安装软件</p>
<p>因为偷懒，为了方便上传文件，先安装aapanel</p>
<ol>
<li><p>aaPanel</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget -O install.sh http://www.aapanel.com/script/install-ubuntu_6.0_en.sh &amp;&amp; bash install.sh forum</span><br></pre></td></tr></table></figure></li>
</ol>
<p><img src="https://raw.githubusercontent.com/HenryVarro666/images/master/images/202204212015069.png" alt="image-20220421191529003"></p>
<blockquote>
<p>aaPanel Internet Address: <a target="_blank" rel="noopener" href="http://43.131.36.132:7800/629f191d">http://43.131.36.132:7800/629f191d</a><br>aaPanel Internal Address: <a target="_blank" rel="noopener" href="http://10.0.0.8:7800/629f191d">http://10.0.0.8:7800/629f191d</a><br>username: idzkykqj<br>password: 1d4e250e</p>
</blockquote>
<p><u>要去控制台的security group开放端口！！！</u></p>
<h2 id="Java"><a href="#Java" class="headerlink" title="Java"></a>Java</h2><p>&#x2F;usr&#x2F;lib&#x2F;jvm</p>
<p>tar -zxvf .&#x2F;jdk-8u162-linux-x64.tar.gz</p>
<p>vim ~&#x2F;.bashrc</p>
<blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_162</span><br><span class="line">export JRE_HOME=$&#123;JAVA_HOME&#125;/jre</span><br><span class="line">export CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/lib</span><br><span class="line">export PATH=$&#123;JAVA_HOME&#125;/bin:$PATH</span><br></pre></td></tr></table></figure>
</blockquote>
<p>source ~&#x2F;.bashrc</p>
<p>java -version</p>
<p><img src="https://raw.githubusercontent.com/HenryVarro666/images/master/images/202204212121300.png" alt="image-20220421202153235"></p>
<h2 id="Hadoop3-1-3"><a href="#Hadoop3-1-3" class="headerlink" title="Hadoop3.1.3"></a>Hadoop3.1.3</h2><p>tar -zxvf  hadoop-3.1.3.tar.gz</p>
<p>sudo mv .&#x2F;hadoop-3.1.3&#x2F; .&#x2F;hadoop </p>
<p>sudo chown -R hadoop .&#x2F;hadoop</p>
<p>到&#x2F;usr&#x2F;local&#x2F;hadoop文件夹，执行</p>
<p>.bin&#x2F;hadoop version</p>
<p><img src="https://raw.githubusercontent.com/HenryVarro666/images/master/images/202204212126250.png" alt="image-20220421202620196"></p>
<p>hadoop文件夹下创建input文件夹</p>
<h3 id="Hadoop伪分布式配置"><a href="#Hadoop伪分布式配置" class="headerlink" title="Hadoop伪分布式配置"></a>Hadoop伪分布式配置</h3><p>Hadoop 的配置文件位于 &#x2F;usr&#x2F;local&#x2F;hadoop&#x2F;etc&#x2F;hadoop&#x2F; 中，伪分布式需要修改2个配置文件 <strong>core-site.xml</strong> 和 <strong>hdfs-site.xml</strong> 。Hadoop的配置文件是 xml 格式，每个配置以声明 property 的 name 和 value 的方式来实现。</p>
<p>&#x2F;etc&#x2F;hadoop&#x2F;core-site.xml</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;file:/usr/local/hadoop/tmp&lt;/value&gt;</span><br><span class="line">        &lt;description&gt;Abase for other temporary directories.&lt;/description&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>

<p>&#x2F;etc&#x2F;hadoop&#x2F;hdfs-site.xml</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;1&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/name&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/data&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>

<blockquote>
<p><em>Hadoop配置文件说明</em></p>
<p>Hadoop 的运行方式是由配置文件决定的（运行 Hadoop 时会读取配置文件），因此如果需要从伪分布式模式切换回非分布式模式，需要删除 core-site.xml 中的配置项。</p>
<p>此外，伪分布式虽然只需要配置 fs.defaultFS 和 dfs.replication 就可以运行（官方教程如此），不过若没有配置 hadoop.tmp.dir 参数，则默认使用的临时目录为 &#x2F;tmp&#x2F;hadoo-hadoop，而这个目录在重启时有可能被系统清理掉，导致必须重新执行 format 才行。所以我们进行了设置，同时也指定 dfs.namenode.name.dir 和 dfs.datanode.data.dir，否则在接下来的步骤中可能会出错。</p>
</blockquote>
<p>配置完成后，执行 NameNode 的格式化:</p>
<p>cd &#x2F;usr&#x2F;local&#x2F;hadoop</p>
<p>.&#x2F;bin&#x2F;hdfs namenode -format</p>
<p>接着开启 NameNode 和 DataNode 守护进程。</p>
<p>cd &#x2F;usr&#x2F;local&#x2F;hadoop<br>.&#x2F;sbin&#x2F;start-dfs.sh  #start-dfs.sh是个完整的可执行文件，中间没有空格</p>
<hr>
<p>sudo apt-get install ssh openssh-server</p>
<p>ssh localhost</p>
<p>sudo service ssh start</p>
<p>ps -e | grep sshd</p>
<p><img src="https://raw.githubusercontent.com/HenryVarro666/images/master/images/202204212146090.png" alt="image-20220421204614032"></p>
<h4 id="报错"><a href="#报错" class="headerlink" title="报错"></a>报错</h4><p><img src="https://raw.githubusercontent.com/HenryVarro666/images/master/images/202204212150475.png" alt="image-20220421205036419"></p>
<h3 id="创建Hadoop用户"><a href="#创建Hadoop用户" class="headerlink" title="创建Hadoop用户"></a>创建Hadoop用户</h3><p>sudo passwd hadoop</p>
<p>sudo adduser hadoop sudo</p>
<p>sudo apt-get update</p>
<p>切换用户之后</p>
<p><img src="https://raw.githubusercontent.com/HenryVarro666/images/master/images/202204212155536.png" alt="image-20220421205550459"></p>
<p>如果在这一步时提示 <strong>Error: JAVA_HOME is not set and could not be found.</strong> 的错误，则说明之前设置 JAVA_HOME 环境变量那边就没设置好，请按教程先设置好 JAVA_HOME 变量，否则后面的过程都是进行不下去的。如果已经按照前面教程在.bashrc文件中设置了JAVA_HOME，还是出现 <strong>Error: JAVA_HOME is not set and could not be found.</strong> 的错误，那么，请到hadoop的安装目录修改配置文件“&#x2F;usr&#x2F;local&#x2F;hadoop&#x2F;etc&#x2F;hadoop&#x2F;hadoop-env.sh”，在里面找到“export JAVA_HOME&#x3D;${JAVA_HOME}”这行，然后，把它修改成JAVA安装路径的具体地址，比如，“export JAVA_HOME&#x3D;&#x2F;usr&#x2F;lib&#x2F;jvm&#x2F;default-java”，然后，再次启动Hadoop。</p>
<p>切换用户之后， 需要生成密钥，就可以无密码登录ssh</p>
<p>去.ssh</p>
<blockquote>
<ol>
<li>cd ~&#x2F;.ssh&#x2F;                     <em># 若没有该目录，请先执行一次ssh localhost</em></li>
<li>ssh-keygen -t rsa              <em># 会有提示，都按回车就可以</em></li>
<li>cat .&#x2F;id_rsa.pub &gt;&gt; .&#x2F;authorized_keys  # 加入授权</li>
</ol>
</blockquote>
<p>开启守护进程后通过jps指令查看结果</p>
<p><img src="https://raw.githubusercontent.com/HenryVarro666/images/master/images/202204212219514.png" alt="image-20220421211926456"></p>
<blockquote>
<p>若成功启动则会列出如下进程: “NameNode”、”DataNode” 和 “SecondaryNameNode”（如果 SecondaryNameNode 没有启动，请运行 sbin&#x2F;stop-dfs.sh 关闭进程，然后再次尝试启动尝试）。如果没有 NameNode 或 DataNode ，那就是配置不成功，请仔细检查之前步骤，或通过查看启动日志排查原因。 </p>
</blockquote>
<h4 id="重新格式化-NameNode"><a href="#重新格式化-NameNode" class="headerlink" title="重新格式化 NameNode"></a>重新格式化 NameNode</h4><p>.&#x2F;bin&#x2F;hdfs namenode -format</p>
<h4 id="启动Hadoop"><a href="#启动Hadoop" class="headerlink" title="启动Hadoop"></a>启动Hadoop</h4><p>.&#x2F;sbin&#x2F;start-dfs.sh</p>
<h4 id="关闭hadoop"><a href="#关闭hadoop" class="headerlink" title="关闭hadoop"></a>关闭hadoop</h4><p>.&#x2F;sbin&#x2F;stop-dfs.sh</p>
<p><strong>若是 DataNode 没有启动</strong>，可尝试如下的方法（注意这会删除 HDFS 中原有的所有数据，如果原有的数据很重要请不要这样做）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/hadoop</span><br><span class="line">./sbin/stop-dfs.sh   # 关闭</span><br><span class="line">rm -r ./tmp     # 删除 tmp 文件，注意这会删除 HDFS 中原有的所有数据</span><br><span class="line">./bin/hdfs namenode -format   # 重新格式化 NameNode</span><br><span class="line">./sbin/start-dfs.sh  # 重启</span><br></pre></td></tr></table></figure>





<p>Hadoop 运行程序时，输出目录不能存在，否则会提示错误 “org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory hdfs:&#x2F;&#x2F;localhost:9000&#x2F;user&#x2F;hadoop&#x2F;output already exists” ，因此若要再次执行，需要执行如下命令删除 output 文件夹:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/hdfs dfs -rm -r output    # 删除 output 文件夹</span><br></pre></td></tr></table></figure>

<p>运行 Hadoop 程序时，为了防止覆盖结果，程序指定的输出目录（如 output）不能存在，否则会提示错误，因此运行前需要先删除输出目录。在实际开发应用程序时，可考虑在程序中加上如下代码，能在每次运行时自动删除输出目录，避免繁琐的命令行操作：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Configuration conf = new Configuration();</span><br><span class="line">Job job = new Job(conf);</span><br><span class="line"></span><br><span class="line">/* 删除输出目录 */</span><br><span class="line">Path outputPath = new Path(args[1]);</span><br><span class="line">outputPath.getFileSystem(conf).delete(outputPath, true);</span><br></pre></td></tr></table></figure>

<h2 id="Spark"><a href="#Spark" class="headerlink" title="Spark"></a>Spark</h2><p>压缩文件放到local，解压</p>
<p>重命名</p>
<p>sudo mv .&#x2F;spark-2.4.0-bin-without-hadoop&#x2F; .&#x2F;spark</p>
<p>改权限</p>
<p>sudo chown -R hadoop:hadoop .&#x2F;spark          <em># 此处的 hadoop 为你的用户名</em></p>
<p>修改spark的配置文件spark-env.sh</p>
<p>cp .&#x2F;conf&#x2F;spark-env.sh.template .&#x2F;conf&#x2F;spark-env.sh</p>
<p>在spark-env.sh第一行添加</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export SPARK_DIST_CLASSPATH=$(/usr/local/hadoop/bin/hadoop classpath)</span><br></pre></td></tr></table></figure>

<p>配置完成后就可以直接使用，不需要像Hadoop运行启动命令。<br>通过运行Spark自带的示例，验证Spark是否安装成功。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/spark</span><br><span class="line"></span><br><span class="line">bin/run-example SparkPi</span><br></pre></td></tr></table></figure>

<p>但是执行时会输出非常多的运行信息，输出结果不容易找到，可以通过 grep 命令进行过滤（命令中的 2&gt;&amp;1 可以将所有的信息都输出到 stdout 中，否则由于输出日志的性质，还是会输出到屏幕中）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/spark</span><br><span class="line">bin/run-example SparkPi 2&gt;&amp;1 | grep &quot;Pi is&quot;</span><br></pre></td></tr></table></figure>

<p><img src="https://raw.githubusercontent.com/HenryVarro666/images/master/images/202204212243291.png" alt="image-20220421214323224"></p>
<h4 id="启动spark-shell"><a href="#启动spark-shell" class="headerlink" title="启动spark shell"></a>启动spark shell</h4><p>bin&#x2F;spark-shell</p>
<p><img src="https://raw.githubusercontent.com/HenryVarro666/images/master/images/202204212244465.png" alt="image-20220421214437380"></p>
<h4 id="退出Spark-shell"><a href="#退出Spark-shell" class="headerlink" title="退出Spark  shell"></a>退出Spark  shell</h4><p>:q</p>
<h2 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h2><p><a target="_blank" rel="noopener" href="http://dblab.xmu.edu.cn/blog/1689-2/">Spark2.1.0+入门：Spark的安装和使用(Python版)_厦大数据库实验室博客 (xmu.edu.cn)</a></p>
<h2 id="Anaconda"><a href="#Anaconda" class="headerlink" title="Anaconda"></a>Anaconda</h2><p>python3.9</p>
<p>压缩文件保存到 &#x2F;home&#x2F;hadoop</p>
<p>安装</p>
<p>bash Anaconda3-2021.11-Linux-x86_64.sh</p>
<p>默认的安装路径</p>
<p><img src="https://raw.githubusercontent.com/HenryVarro666/images/master/images/202204212304710.png" alt="image-20220421220420640"></p>
<p>conda初始化（设置环境变量）</p>
<p><img src="https://raw.githubusercontent.com/HenryVarro666/images/master/images/202204212309755.png" alt="image-20220421220908662"></p>
<p>reload the shell</p>
<p>必须先关闭终端再打开才有效</p>
<p>exec $SHELL</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">exec</span> bash</span><br></pre></td></tr></table></figure>

<p>检查anaconda 版本</p>
<blockquote>
<p>这时前面多了个base，指的是当前环境。可以通过</p>
<p>conda config –set auto_activate_base false</p>
<p>关闭</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/HenryVarro666/images/master/images/202204212312632.png" alt="image-20220421221252559"></p>
<p>装完anaconda，python也有了</p>
<p><img src="https://raw.githubusercontent.com/HenryVarro666/images/master/images/202204212314047.png" alt="image-20220421221421987"></p>
<hr>
<p>复制粘贴</p>
<p>1，将数据从windows复制到ubuntu：你首先用ctrl+c复制内容，然后在ubuntu的终端下按下鼠标的滚轮。</p>
<p>2，将数据从ubuntu复制到widnows：你首先选中终端里要复制的内容（不要按ctrl+c，选中即复制），然后在windows中按下ctrl+v。</p>
<hr>
<h3 id="访问服务器的jupyter-notebook"><a href="#访问服务器的jupyter-notebook" class="headerlink" title="访问服务器的jupyter notebook"></a>访问服务器的jupyter notebook</h3><p><a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1769288">远程访问云服务器的jupyter notebook</a></p>
<p>ipython</p>
<p>In [1]: from notebook.auth import passwd                                        </p>
<p>In [2]: passwd()<br>Enter password:<br>Verify password: </p>
<blockquote>
<p>Out[3]: ‘argon2:$argon2id$v&#x3D;19$m&#x3D;10240,t&#x3D;10,p&#x3D;8$kjPCgB+Ux8SVOHiTxb2peg$0GiCPNnIAdOYH4m6EBYbNA’’</p>
</blockquote>
<p>In [3]: exit()</p>
<p>生成配置文件</p>
<p>jupyter notebook –generate-config</p>
<p>修改配置文件</p>
<p>vim ~&#x2F;.jupyter&#x2F;jupyter_notebook_config.py</p>
<p> 用 <strong>&#x2F;</strong> 查找内容并修改注释为以下内容然后**:wq**保存退出即可。字符串前加’u’表示后面的字符串以Unicode格式进行编码，防止因为字符串存储格式不同而导致解析出错。</p>
<blockquote>
<p>c.NotebookApp.allow_remote_access &#x3D; True   # 允许外部访问<br>c.NotebookApp.ip&#x3D;’*’                       # 设置所有ip皆可访问<br>c.NotebookApp.password &#x3D; u’sha1:salt:hashed-password’  # 刚才生成的密钥’<br>c.NotebookApp.open_browser &#x3D; False       # 禁止自动打开浏览器<br>c.NotebookApp.port &#x3D; 8888               # 任意指定一个不冲突的端口<br>c.NotebookApp.notebook_dir &#x3D; ‘&#x2F;home&#x2F;hadoop&#x2F;jupyterproject&#x2F;‘ #默认文件路径<br>c.NotebookApp.allow_root &#x3D; True          # 允许root身份运行jupyter notebook</p>
</blockquote>
<p>除了在阿里云官网控制台的安全组中添加相应端口外，还要在<a target="_blank" rel="noopener" href="https://cloud.tencent.com/product/cvm?from=10680">云服务器</a>中也相应地开放端口。</p>
<blockquote>
<p>sudo su root<br>ufw allow 8888<br>ufw reload<br>ufw status</p>
</blockquote>
<p>在hadoop身份下运行jupyter notebook，ip + 端口就可以访问了</p>
<p><img src="https://raw.githubusercontent.com/HenryVarro666/images/master/images/202204212356322.png" alt="image-20220421225605227"></p>
<h1 id="Jupyter-Notebook-服务器后台保持运行或关闭"><a href="#Jupyter-Notebook-服务器后台保持运行或关闭" class="headerlink" title="Jupyter Notebook 服务器后台保持运行或关闭"></a>Jupyter Notebook 服务器后台保持运行或关闭</h1><p>后台开</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup  jupyter notebook --allow-root&amp;</span><br></pre></td></tr></table></figure>

<p>后台关</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps -aux | grep jupyter</span><br></pre></td></tr></table></figure>

<p>找到PID之后</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kill -9 PID</span><br></pre></td></tr></table></figure>



<h1 id="！PySpark和Spark"><a href="#！PySpark和Spark" class="headerlink" title="！PySpark和Spark"></a>！PySpark和Spark</h1><p>Spark: 原生语言为scala</p>
<p>PySpark: 使用了python api对spark进行交互</p>
<hr>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/Gscsd_T/article/details/103438881">个人对 PySpark 的看法和见解</a></p>
<p>spark这个框架，基于hadoop，spark是基于内存的（hadoop基于磁盘的）</p>
<p>pyspark是spark用python写的api接口，内存读写速度肯定比磁盘快</p>
<h2 id="配置Jupyter-Notebook实现和PySpark交互"><a href="#配置Jupyter-Notebook实现和PySpark交互" class="headerlink" title="配置Jupyter Notebook实现和PySpark交互"></a>配置Jupyter Notebook实现和PySpark交互</h2><p><a target="_blank" rel="noopener" href="http://dblab.xmu.edu.cn/blog/2575-2/">http://dblab.xmu.edu.cn/blog/2575-2/</a></p>
<h1 id="其他技术"><a href="#其他技术" class="headerlink" title="其他技术"></a>其他技术</h1><h3 id="Flink-？？？"><a href="#Flink-？？？" class="headerlink" title="Flink ？？？"></a>Flink ？？？</h3><h3 id="Flume-？？？"><a href="#Flume-？？？" class="headerlink" title="Flume ？？？"></a>Flume ？？？</h3><h5 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h5><ol>
<li><p>Flume可以将应用产生的数据存储到任何集中存储器中，比如HDFS,HBase</p>
</li>
<li><p>当收集数据的速度超过将写入数据的时候，也就是当收集信息遇到峰值时，这时候收集的信息非常大，甚至超过了系统的写入数据能力，这时候，Flume会在数据生产者和数据收容器间做出调整，保证其能够在两者之间提供平稳的数据.</p>
</li>
<li><p>提供上下文路由特征</p>
</li>
<li><p>Flume的管道是基于事务，保证了数据在传送和接收时的一致性.</p>
</li>
<li><p>Flume是可靠的，容错性高的，可升级的，易管理的,并且可定制的。</p>
</li>
</ol>
<h5 id="具有特征"><a href="#具有特征" class="headerlink" title="具有特征"></a>具有特征</h5><ol>
<li><p>Flume可以高效率的将多个<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E7%BD%91%E7%AB%99%E6%9C%8D%E5%8A%A1%E5%99%A8/8156379">网站服务器</a>中收集的日志信息存入HDFS&#x2F;HBase中</p>
</li>
<li><p>使用Flume，我们可以将从多个服务器中获取的数据迅速的移交给Hadoop中</p>
</li>
<li><p>除了日志信息，Flume同时也可以用来接入收集规模宏大的社交网络节点事件数据，比如facebook,twitter,电商网站如亚马逊，flipkart等</p>
</li>
<li><p>支持各种接入资源数据的类型以及接出数据类型</p>
</li>
<li><p>支持多路径流量，多管道接入流量，多管道接出流量，上下文路由等</p>
</li>
<li><p>可以被水平扩展</p>
</li>
</ol>
<h3 id="AWS-EKS-？？？"><a href="#AWS-EKS-？？？" class="headerlink" title="AWS EKS ？？？"></a>AWS EKS ？？？</h3><p>数据存储</p>
<p><a target="_blank" rel="noopener" href="https://aws.amazon.com/cn/ekss">https://aws.amazon.com/cn/ekss</a></p>
<h3 id="Windows-or-Ubuntu"><a href="#Windows-or-Ubuntu" class="headerlink" title="Windows or Ubuntu ? ? ?"></a>Windows or Ubuntu ? ? ?</h3><p>winutils</p>
<h3 id="Hadoop节点？？？"><a href="#Hadoop节点？？？" class="headerlink" title="Hadoop节点？？？"></a>Hadoop节点？？？</h3><p>cluster</p>
<p>node</p>
<hr>
<h1 id="Comment"><a href="#Comment" class="headerlink" title="Comment"></a>Comment</h1><p>为了方便spark读取生成RDD或者DataFrame，首先将us-counties.csv转换为.txt格式文件us-counties.txt。转换操作使用python实现，代码组织在toTxt.py中</p>
<p><u>~&#x2F;home&#x2F;hadoop&#x2F;</u></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment">#.csv-&gt;.txt</span></span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;/home/hadoop/us-counties.csv&#x27;</span>)</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;/home/hadoop/us-counties.txt&#x27;</span>,<span class="string">&#x27;a+&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> data.values:</span><br><span class="line">        f.write((<span class="built_in">str</span>(line[<span class="number">0</span>])+<span class="string">&#x27;\t&#x27;</span>+<span class="built_in">str</span>(line[<span class="number">1</span>])+<span class="string">&#x27;\t&#x27;</span></span><br><span class="line">                +<span class="built_in">str</span>(line[<span class="number">2</span>])+<span class="string">&#x27;\t&#x27;</span>+<span class="built_in">str</span>(line[<span class="number">3</span>])+<span class="string">&#x27;\t&#x27;</span>+<span class="built_in">str</span>(line[<span class="number">4</span>])+<span class="string">&#x27;\n&#x27;</span>))</span><br></pre></td></tr></table></figure>





<p>Upload “&#x2F;home&#x2F;hadoop&#x2F;us-counties.txt” from the local filesystem to the HDFS filesystem at “&#x2F;user&#x2F;hadoop&#x2F;us-counties.txt “</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/hdfs dfs -put /home/hadoop/us-counties.txt /user/hadoop</span><br></pre></td></tr></table></figure>

<p>在<u>&#x2F;usr&#x2F;local&#x2F;hadoop</u>这个路径里面</p>
<p>失败了。因为没有user&#x2F;hadoop</p>
<p>所以这里需要先创建用户目录</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">e</span><br></pre></td></tr></table></figure>







<blockquote>
<p> 2022-04-28 21:19:53,534 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted &#x3D; false, remoteHostTrusted &#x3D; false</p>
</blockquote>
<p>（这个暂时不管）</p>
<p><img src="https://raw.githubusercontent.com/HenryVarro666/images/master/images/202204281044123.png" alt="image-20220428094401029"></p>
<p>没找到在哪，但就是成功了</p>
<p><img src="https://raw.githubusercontent.com/HenryVarro666/images/master/images/202204281101626.png" alt="image-20220428100151546"></p>
<p>HDFS文件系统的根目录是&#x2F;，用户主目录是&#x2F;user&#x2F;[hadoop用户名]</p>
<p>HDFS上传文件命令:hadoop fs -put </p>
<p>HDFS下载文件命令:hadoop fs -get</p>
<p>HDFS储存文件目录实在:tmp&#x2F;dfs&#x2F;data&#x2F;current&#x2F;finalized&#x2F;subdir0&#x2F;subdir0&#x2F;</p>
<p>#tmp是在配置hdfs-site.xml是所配置的文件夹</p>
<p>tmp&#x2F;dfs&#x2F;name&#x2F;current&#x2F;VERSION下存储DataNode的clusterID</p>
<p><img src="https://raw.githubusercontent.com/HenryVarro666/images/master/images/202204281047487.png" alt="image-20220428094754399"></p>
<p>这个就是添加路径</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/Y_6155/article/details/110108809">https://blog.csdn.net/Y_6155/article/details/110108809</a></p>
<hr>
<p>上述Spark计算结果保存.json文件，方便后续可视化处理</p>
<p>由于使用Python读取HDFS文件系统不太方便，故将HDFS上结果文件转储到本地文件系统中，使用以下命令：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -get /user/hadoop/result1.json/*.json /home/hadoop/jupyternotebook/result1</span><br></pre></td></tr></table></figure>

<p>对于result2等结果文件，使用相同命令，只需要改一下路径即可。</p>
<p>失败</p>
<p>.&#x2F;bin&#x2F;hdfs dfs -mkdir &#x2F;user&#x2F;hadoop&#x2F;input</p>
<blockquote>
<p>伪分布式运行 MapReduce 作业的方式跟单机模式相同，区别在于伪分布式读取的是HDFS中的文件（可以将单机步骤中创建的本地 input 文件夹，输出结果 output 文件夹都删掉来验证这一点）</p>
</blockquote>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Ubuntu/" rel="tag"># Ubuntu</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/04/21/Ubuntu%E4%BD%BF%E7%94%A8root%E7%94%A8%E6%88%B7%E7%99%BB%E5%BD%95instance/" rel="prev" title="Ubuntu使用root用户登录instance">
      <i class="fa fa-chevron-left"></i> Ubuntu使用root用户登录instance
    </a></div>
      <div class="post-nav-item"></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Java"><span class="nav-number">1.</span> <span class="nav-text">Java</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Hadoop3-1-3"><span class="nav-number">2.</span> <span class="nav-text">Hadoop3.1.3</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Hadoop%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E9%85%8D%E7%BD%AE"><span class="nav-number">2.1.</span> <span class="nav-text">Hadoop伪分布式配置</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%8A%A5%E9%94%99"><span class="nav-number">2.1.1.</span> <span class="nav-text">报错</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%9B%E5%BB%BAHadoop%E7%94%A8%E6%88%B7"><span class="nav-number">2.2.</span> <span class="nav-text">创建Hadoop用户</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%87%8D%E6%96%B0%E6%A0%BC%E5%BC%8F%E5%8C%96-NameNode"><span class="nav-number">2.2.1.</span> <span class="nav-text">重新格式化 NameNode</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%90%AF%E5%8A%A8Hadoop"><span class="nav-number">2.2.2.</span> <span class="nav-text">启动Hadoop</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%85%B3%E9%97%ADhadoop"><span class="nav-number">2.2.3.</span> <span class="nav-text">关闭hadoop</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Spark"><span class="nav-number">3.</span> <span class="nav-text">Spark</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%90%AF%E5%8A%A8spark-shell"><span class="nav-number">3.0.1.</span> <span class="nav-text">启动spark shell</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%80%80%E5%87%BASpark-shell"><span class="nav-number">3.0.2.</span> <span class="nav-text">退出Spark  shell</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Python"><span class="nav-number">4.</span> <span class="nav-text">Python</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Anaconda"><span class="nav-number">5.</span> <span class="nav-text">Anaconda</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%BF%E9%97%AE%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84jupyter-notebook"><span class="nav-number">5.1.</span> <span class="nav-text">访问服务器的jupyter notebook</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Jupyter-Notebook-%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%90%8E%E5%8F%B0%E4%BF%9D%E6%8C%81%E8%BF%90%E8%A1%8C%E6%88%96%E5%85%B3%E9%97%AD"><span class="nav-number"></span> <span class="nav-text">Jupyter Notebook 服务器后台保持运行或关闭</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%EF%BC%81PySpark%E5%92%8CSpark"><span class="nav-number"></span> <span class="nav-text">！PySpark和Spark</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%85%8D%E7%BD%AEJupyter-Notebook%E5%AE%9E%E7%8E%B0%E5%92%8CPySpark%E4%BA%A4%E4%BA%92"><span class="nav-number">1.</span> <span class="nav-text">配置Jupyter Notebook实现和PySpark交互</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%85%B6%E4%BB%96%E6%8A%80%E6%9C%AF"><span class="nav-number"></span> <span class="nav-text">其他技术</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Flink-%EF%BC%9F%EF%BC%9F%EF%BC%9F"><span class="nav-number">0.1.</span> <span class="nav-text">Flink ？？？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Flume-%EF%BC%9F%EF%BC%9F%EF%BC%9F"><span class="nav-number">0.2.</span> <span class="nav-text">Flume ？？？</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%BC%98%E5%8A%BF"><span class="nav-number">0.2.0.1.</span> <span class="nav-text">优势</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%85%B7%E6%9C%89%E7%89%B9%E5%BE%81"><span class="nav-number">0.2.0.2.</span> <span class="nav-text">具有特征</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#AWS-EKS-%EF%BC%9F%EF%BC%9F%EF%BC%9F"><span class="nav-number">0.3.</span> <span class="nav-text">AWS EKS ？？？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Windows-or-Ubuntu"><span class="nav-number">0.4.</span> <span class="nav-text">Windows or Ubuntu ? ? ?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hadoop%E8%8A%82%E7%82%B9%EF%BC%9F%EF%BC%9F%EF%BC%9F"><span class="nav-number">0.5.</span> <span class="nav-text">Hadoop节点？？？</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Comment"><span class="nav-number"></span> <span class="nav-text">Comment</span></a></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Chao Cao"
      src="/uploads/head2.jpg">
  <p class="site-author-name" itemprop="name">Chao Cao</p>
  <div class="site-description" itemprop="description">为天地立心，为生民立命，为往圣继绝学，为万世开太平</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">73</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">16</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/HenryVarro666" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;HenryVarro666" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:ccao2679@umd.edu" title="E-Mail → mailto:ccao2679@umd.edu" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="http://ccao2679.com/" title="http:&#x2F;&#x2F;ccao2679.com" rel="noopener" target="_blank">Chao の Blog</a>
        </li>
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Chao Cao</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">Symbols count total: </span>
    <span title="Symbols count total">189k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">Reading time total &asymp;</span>
    <span title="Reading time total">2:52</span>
</div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>









<script>
document.querySelectorAll('.pdfobject-container').forEach(element => {
  let url = element.dataset.target;
  let pdfOpenParams = {
    navpanes : 0,
    toolbar  : 0,
    statusbar: 0,
    pagemode : 'thumbs',
    view     : 'FitH'
  };
  let pdfOpenFragment = '#' + Object.entries(pdfOpenParams).map(([key, value]) => `${key}=${encodeURIComponent(value)}`).join('&');
  let fullURL = `/lib/pdf/web/viewer.html?file=${encodeURIComponent(url)}${pdfOpenFragment}`;

  if (NexT.utils.supportsPDFs()) {
    element.innerHTML = `<embed class="pdfobject" src="${url + pdfOpenFragment}" type="application/pdf" style="height: ${element.dataset.height};">`;
  } else {
    element.innerHTML = `<iframe src="${fullURL}" style="height: ${element.dataset.height};" frameborder="0"></iframe>`;
  }
});
</script>




  

  

</body>
</html>
